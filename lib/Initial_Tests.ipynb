{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb44b73e",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a352ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For text processing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# For model building\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41522c",
   "metadata": {},
   "source": [
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4801e24a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Path to dataset files: C:\\Users\\Leo\\.cache\\kagglehub\\datasets\\shivamb\\go-emotions-google-emotions-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"shivamb/go-emotions-google-emotions-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9938d5b7",
   "metadata": {},
   "source": [
    "Load and display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6029d020",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text  \\\n",
      "0  eew5j0j                                    That game hurt.   \n",
      "1  eemcysk   >sexuality shouldnâ€™t be a grouping category I...   \n",
      "2  ed2mah1     You do right, if you don't care then fuck 'em!   \n",
      "3  eeibobj                                 Man I love reddit.   \n",
      "4  eda6yn6  [NAME] was nowhere near them, he was by the Fa...   \n",
      "\n",
      "   example_very_unclear  admiration  amusement  anger  annoyance  approval  \\\n",
      "0                 False           0          0      0          0         0   \n",
      "1                  True           0          0      0          0         0   \n",
      "2                 False           0          0      0          0         0   \n",
      "3                 False           0          0      0          0         0   \n",
      "4                 False           0          0      0          0         0   \n",
      "\n",
      "   caring  confusion  ...  love  nervousness  optimism  pride  realization  \\\n",
      "0       0          0  ...     0            0         0      0            0   \n",
      "1       0          0  ...     0            0         0      0            0   \n",
      "2       0          0  ...     0            0         0      0            0   \n",
      "3       0          0  ...     1            0         0      0            0   \n",
      "4       0          0  ...     0            0         0      0            0   \n",
      "\n",
      "   relief  remorse  sadness  surprise  neutral  \n",
      "0       0        0        1         0        0  \n",
      "1       0        0        0         0        0  \n",
      "2       0        0        0         0        1  \n",
      "3       0        0        0         0        0  \n",
      "4       0        0        0         0        1  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(path+\"/go_emotions_dataset.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7932d1be",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3c4149",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e4b1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned text:\n",
      "0                                            game hurt\n",
      "1    sexuality shouldnt grouping category make diff...\n",
      "2                              right dont care fuck em\n",
      "3                                      man love reddit\n",
      "4                             name nowhere near falcon\n",
      "5    right considering important document know damn...\n",
      "6    isnt big he still quite popular ive heard thin...\n",
      "7    thats crazy went super religion high school th...\n",
      "8                                   thats adorable asf\n",
      "9    sponge blurb pub quaw haha gurr ha aaa finale ...\n",
      "Name: clean_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK data files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer and define stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize and remove stop words\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]\n",
    "    # Join tokens back to string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "data['clean_text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Display the cleaned text\n",
    "print(\"\\nCleaned text:\")\n",
    "print(data['clean_text'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1893786a",
   "metadata": {},
   "source": [
    "Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b966a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and targets\n",
    "X = data['clean_text']\n",
    "Y = data.loc[:, 'admiration':'neutral']\n",
    "emotion_columns = data.columns[3:-1]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8179087",
   "metadata": {},
   "source": [
    "Build the Model: Use a pipeline to vectorize text and train a logistic regression classifier in a one-vs-rest fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e2b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(solver='liblinear')))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91efc2",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d811f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.66      0.25      0.36      3456\n",
      "     amusement       0.60      0.29      0.39      1891\n",
      "         anger       0.53      0.08      0.14      1628\n",
      "     annoyance       0.33      0.02      0.03      2722\n",
      "      approval       0.56      0.03      0.06      3418\n",
      "        caring       0.49      0.04      0.07      1147\n",
      "     confusion       0.61      0.03      0.05      1463\n",
      "     curiosity       0.72      0.04      0.07      1941\n",
      "        desire       0.48      0.06      0.11       758\n",
      "disappointment       0.59      0.01      0.02      1671\n",
      "   disapproval       0.42      0.01      0.02      2289\n",
      "       disgust       0.58      0.07      0.13      1074\n",
      " embarrassment       0.54      0.03      0.06       502\n",
      "    excitement       0.57      0.05      0.09      1121\n",
      "          fear       0.63      0.15      0.25       625\n",
      "     gratitude       0.90      0.70      0.79      2330\n",
      "         grief       0.67      0.02      0.03       115\n",
      "           joy       0.49      0.10      0.16      1597\n",
      "          love       0.68      0.37      0.48      1632\n",
      "   nervousness       0.37      0.02      0.04       365\n",
      "      optimism       0.61      0.16      0.25      1769\n",
      "         pride       0.70      0.03      0.05       260\n",
      "   realization       0.59      0.01      0.02      1715\n",
      "        relief       0.00      0.00      0.00       257\n",
      "       remorse       0.45      0.10      0.17       518\n",
      "       sadness       0.57      0.11      0.19      1294\n",
      "      surprise       0.52      0.08      0.13      1074\n",
      "       neutral       0.58      0.17      0.26     11185\n",
      "\n",
      "     micro avg       0.64      0.14      0.23     49817\n",
      "     macro avg       0.55      0.11      0.16     49817\n",
      "  weighted avg       0.57      0.14      0.20     49817\n",
      "   samples avg       0.16      0.15      0.15     49817\n",
      "\n",
      "Accuracy: 0.1368\n",
      "Precision: 0.5503\n",
      "Recall: 0.1076\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, Y_pred, target_names=emotion_columns))\n",
    "\n",
    "# Calculate overall metrics\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='macro', zero_division=0)\n",
    "recall = recall_score(Y_test, Y_pred, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae3abc0",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "070d4f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters:\n",
      "{'clf__estimator__C': 10, 'tfidf__max_df': 0.9, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters to tune\n",
    "parameters = {\n",
    "    'tfidf__max_df': [0.9, 1.0],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'clf__estimator__C': [1, 10]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=3, scoring='f1_macro')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "Y_pred_best = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a829725",
   "metadata": {},
   "source": [
    "Re-evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ef09a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report with Best Model:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.59      0.39      0.47      3456\n",
      "     amusement       0.54      0.37      0.44      1891\n",
      "         anger       0.44      0.18      0.26      1628\n",
      "     annoyance       0.28      0.09      0.14      2722\n",
      "      approval       0.31      0.11      0.16      3418\n",
      "        caring       0.35      0.13      0.19      1147\n",
      "     confusion       0.35      0.11      0.17      1463\n",
      "     curiosity       0.45      0.17      0.25      1941\n",
      "        desire       0.34      0.11      0.17       758\n",
      "disappointment       0.28      0.08      0.12      1671\n",
      "   disapproval       0.32      0.11      0.16      2289\n",
      "       disgust       0.40      0.13      0.19      1074\n",
      " embarrassment       0.47      0.10      0.16       502\n",
      "    excitement       0.39      0.11      0.17      1121\n",
      "          fear       0.54      0.26      0.35       625\n",
      "     gratitude       0.87      0.73      0.79      2330\n",
      "         grief       0.25      0.06      0.10       115\n",
      "           joy       0.48      0.19      0.27      1597\n",
      "          love       0.64      0.47      0.54      1632\n",
      "   nervousness       0.29      0.05      0.09       365\n",
      "      optimism       0.50      0.22      0.30      1769\n",
      "         pride       0.60      0.07      0.12       260\n",
      "   realization       0.29      0.07      0.12      1715\n",
      "        relief       0.41      0.05      0.10       257\n",
      "       remorse       0.49      0.21      0.30       518\n",
      "       sadness       0.46      0.19      0.27      1294\n",
      "      surprise       0.48      0.17      0.25      1074\n",
      "       neutral       0.51      0.33      0.40     11185\n",
      "\n",
      "     micro avg       0.50      0.24      0.33     49817\n",
      "     macro avg       0.44      0.19      0.25     49817\n",
      "  weighted avg       0.46      0.24      0.31     49817\n",
      "   samples avg       0.27      0.25      0.25     49817\n",
      "\n",
      "Best Model Accuracy: 0.2189\n",
      "Best Model Precision: 0.4405\n",
      "Best Model Recall: 0.1885\n"
     ]
    }
   ],
   "source": [
    "# Classification report with the best model\n",
    "print(\"\\nClassification Report with Best Model:\")\n",
    "print(classification_report(Y_test, Y_pred_best, target_names=emotion_columns))\n",
    "\n",
    "# Calculate overall metrics\n",
    "accuracy_best = accuracy_score(Y_test, Y_pred_best)\n",
    "precision_best = precision_score(Y_test, Y_pred_best, average='macro', zero_division=0)\n",
    "recall_best = recall_score(Y_test, Y_pred_best, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"Best Model Accuracy: {accuracy_best:.4f}\")\n",
    "print(f\"Best Model Precision: {precision_best:.4f}\")\n",
    "print(f\"Best Model Recall: {recall_best:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de08c3a5",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493db899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(RandomForestClassifier(random_state=42)))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ed022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, Y_pred, target_names=emotion_columns))\n",
    "\n",
    "# Calculate overall metrics\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='macro', zero_division=0)\n",
    "recall = recall_score(Y_test, Y_pred, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08709d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters to tune\n",
    "parameters = {\n",
    "    'tfidf__max_df': [0.9, 1.0],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__estimator__n_estimators': [100, 200],\n",
    "    'clf__estimator__max_depth': [None, 10, 20],\n",
    "    'clf__estimator__min_samples_split': [2, 5],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    parameters,\n",
    "    cv=3,\n",
    "    scoring='f1_macro',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "Y_pred_best = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report with the best model\n",
    "print(\"\\nClassification Report with Best Model:\")\n",
    "print(classification_report(Y_test, Y_pred_best, target_names=emotion_columns))\n",
    "\n",
    "# Calculate overall metrics\n",
    "accuracy_best = accuracy_score(Y_test, Y_pred_best)\n",
    "precision_best = precision_score(Y_test, Y_pred_best, average='macro', zero_division=0)\n",
    "recall_best = recall_score(Y_test, Y_pred_best, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best:.4f}\")\n",
    "print(f\"Best Model Precision: {precision_best:.4f}\")\n",
    "print(f\"Best Model Recall: {recall_best:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
